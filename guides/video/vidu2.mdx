---
title: "Vidu 2"
keywords: ["Z.AI","vidu","Vidu 2","vidu2"]
description: "Vidu 2 is a next-generation video generation model that strikes a balance between speed and quality. It focuses on image-to-video generation and keyframe-based video creation, supporting 720P resolution for videos up to 4 seconds long. With significantly faster generation speed and reduced cost, it addresses color distortion issues in image-to-video outputs, delivering stable and controllable visuals ideal for e-commerce scenarios. Enhanced semantic understanding between keyframes and improved consistency with multiple reference images make Vidu 2 a highly efficient tool for mass production in pan-entertainment, internet content, anime short series, and advertising."
---

| **Model Version** | **Capabilities**                 | **Duration** | **Resolution** | **Price**     |
| :---------------- | :------------------------------- | :----------- | :------------- | :------------ |
| vidu2-image       | Image-to-Video Generation        | 4s           | 720p           | \$0.2 / video |
| vidu2-start-end   | Start and End Frame              | 4s           | 720p           | \$0.2 / video |
| vidu2-reference   | Reference-based Video Generation | 4s           | 720p           | \$0.4 / video |

### **Capability Description**

- ​**Image-to-Video Generation**​: Generate a video by providing a starting frame or both starting and ending frames along with corresponding text descriptions.
- ​**Start and End Frame**​: Supports input of two images: the first uploaded image is treated as the starting frame, and the second as the ending frame. The model uses these images as input parameters to generate the video.
- ​**Reference-based Video Generation**​: Generate a video from a text prompt; currently supports both a general style and an anime style optimized for animation.

<Info>
  The URL link for the video generated by the model is valid for one day. Please save it as soon as possible if needed.
</Info>

### **Recommended Use Cases**

| Scenario Type                                | Description                                                                                                                                                                                                                                                                                                                                                  |
| :------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **General Entertainment Content Generation** | - Input a single frame or IP elements to quickly generate short videos with coherent storylines and interactive special effects<br />- Supports diverse visual styles from anime-inspired to realistic<br />- Tailored for mass production of UGC creative content on short video platforms                                                                  |
| **​ Anime Short Drama Production**           | - Input static character images or keyframes to generate smooth animated sequences and micro-dramas<br />- Accurately reproduce detailed character movements (e.g., facial expressions)<br />- Supports mass production in various styles such as Chinese and Japanese anime<br />- Designed to meet animation studios’ needs for IP-based content expansion |
| **Advertising & E-commerce Marketing**       | - Input real product images to intelligently generate dynamic advertising videos<br />- Clearly showcase product features such as 3C details and beauty product textures<br />- Automatically adapt to various platform formats, such as vertical videos for Tiktok and horizontal layouts for social feeds                                                  |

### **Resources**

[API Documentation](/api-reference/video/cogvideox-3&vidu): Learn how to call the API.

### **Detailed Description**

1. **Efficient Video Generation Speed**

With optimized model computing architecture, video rendering efficiency is significantly enhanced. This allows daily content teams to respond quickly to trending topics, and enables e-commerce sellers to mass-produce product display videos on demand—greatly reducing content delivery time and helping creators seize traffic windows.

2. **Cost-effective 720P Output**

The cost of generating 720P resolution videos has dropped to 40% of the Q1 version. Small and medium-sized brands can now create batch videos for multiple SKUs, while advertising teams can test creative concepts like "product close-ups \+ scenario storytelling" at a lower cost—meeting full-platform marketing needs without breaking the content budget.

3. **Stable and Controllable Image-to-Video Generation**

The model addresses the "texture color shift" issue—accurately restoring details like the silky glow of satin or the matte finish of leather in clothing videos. In e-commerce scenarios, product colors are displayed more realistically. Dynamic frame compensation is optimized, ensuring smooth, shake-free motion for rotating 3C products or hand demonstrations in beauty tutorials. Multiple visual styles are supported, enabling eye-catching content like “product close-up \+ stylized camera movement,” ideal for e-commerce main images and short-form promotional videos.

<video src="https://cdn.bigmodel.cn/static/platform/videos/usage-guide/vidu/2.0-1.mp4" controls />

4. **Semantically Enhanced Keyframe Transition**

The model strikes a balance between creativity and stability, delivering significantly improved performance and semantic understanding—making it the optimal solution for keyframe-based video generation. By accurately analyzing scene logic and action continuity, transitions between frames are smooth and natural, enhancing narrative coherence throughout the content.

5. **Semantically Enhanced Keyframe Transition**

The model strikes a balance between creativity and stability, delivering significantly improved performance and semantic understanding—making it the optimal solution for keyframe-based video generation. By accurately analyzing scene logic and action continuity, transitions between frames are smooth and natural, enhancing narrative coherence throughout the content.

![020f485a Fb03 4698 8a6c F9f89b5b7361 Jpe](/images/020f485a-fb03-4698-8a6c-f9f89b5b7361.jpeg)

<video src="https://cdn.bigmodel.cn/static/platform/videos/usage-guide/vidu/2.0-2.mp4" controls />

### **Example**

#### Image-to-Video Generation
<Tabs>
    <Tab title="Curl">
        ```json 
        curl --location --request POST 'https://api.z.ai/api/paas/v4/videos/generations' \
        --header 'Authorization: Bearer {your apikey}' \
        --header 'Content-Type: application/json' \
        --data-raw '{
            "model":"vidu2-image",
            "image_url":"https://example.com/path/to/your/image.jpg",
            "prompt":"Peter Rabbit drives a small car along the road, his face filled with joy and happiness.",
            "duration":4,
            "size":"720x480",
            "movement_amplitude":"auto"
        }'
        ```
    </Tab>
    <Tab title="Python">
        **Install SDK**
        ```bash
        # Install latest version
        pip install zai-sdk

        # Or specify version
        pip install zai-sdk==0.0.2
        ```

        **Verify Installation**
        ```python
        import zai
        print(zai.__version__)
        ```

        ```python
        from zai import ZaiClient

        # Initialize the client, please replace your-api-key with your own APIKey.
        client = ZaiClient(api_key="your-api-key")

        # Video generation example from images.
        response = client.videos.generations(
            model="vidu2-image",
            image_url="https://example.com/path/to/your/image.jpg",
            prompt="Peter Rabbit is driving a small car, cruising on the road, with a face full of happiness and joy.",
            duration=4,
            size="1280x720",
            movement_amplitude="auto"
        )

        # Print the response result.
        print(response)
        ```
    </Tab>
    <Tab title="Java">

        **Install SDK**

        **Maven**
        ```xml
        <dependency>
            <groupId>ai.z.openapi</groupId>
            <artifactId>zai-sdk</artifactId>
            <version>0.0.2</version>
        </dependency>
        ```

        **Gradle (Groovy)**
        ```groovy
        implementation 'ai.z.openapi:zai-sdk:0.0.2'
        ```

        ```java
        import ai.z.openapi.ZaiClient;
        import ai.z.openapi.service.videos.VideoCreateParams;
        import ai.z.openapi.service.videos.VideosResponse;

        public class Vidu2Example {
            public static void main(String[] args) throws InterruptedException {
                String apiKey = "your_api_key"; // Please fill in your own APIKey.
                ZaiClient client = ZaiClient.builder().apiKey(apiKey).build();

                // Construct video generation request parameters.
                VideoCreateParams request = VideoCreateParams.builder()
                    .model("vidu2-image")
                    .imageUrl("https://example.com/path/to/your/image.jpg")
                    .prompt("Peter Rabbit is driving a small car, cruising on the road, with a face full of happiness and joy.")
                    .duration(4)
                    .size("1280x720")
                    .build();

                // Initiate video generation request.
                VideosResponse response = client.videos().videoGenerations(request);
                System.out.println(response.getData());
                
                // Wait for 10 minutes, then asynchronously retrieve the final generated video using the task ID.
                Thread.sleep(600000L);
                VideosResponse videosResponse = client.videos().videoGenerationsResult(response.getData().getId());
                System.out.println(videosResponse.getData().getVideoResult());
            }
        }
        ```
    </Tab>
</Tabs>

#### Start and End Frame
<Tabs>
    <Tab title="Curl">
        ```json 
        curl --location --request POST 'https://api.z.ai/api/paas/v4/videos/generations' \
        --header 'Authorization: Bearer {your apikey}' \
        --header 'Content-Type: application/json' \
        --data-raw '{
            "model":"vidu2-start-end",
            "image_url":["https://example.com/path/to/your/image1.jpg","https://example.com/path/to/your/image2.jpg"],
            "prompt":"Peter Rabbit drives a small car along the road, his face filled with joy and happiness.",
            "duration":4,
            "size":"720x480",
            "movement_amplitude":"auto"
        }'
        ```
    </Tab>
    <Tab title="Python">
        ```python
        from zai import ZaiClient

        # Initialize the client, please replace "your-api-key" with your own APIKey.
        client = ZaiClient(api_key="your-api-key")

        # Define URLs for first frame and last frame
        sample_first_frame = "https://gd-hbimg.huaban.com/ccee58d77afe8f5e17a572246b1994f7e027657fe9e6-qD66In_fw1200webp"
        sample_last_frame = "https://gd-hbimg.huaban.com/cc2601d568a72d18d90b2cc7f1065b16b2d693f7fa3f7-hDAwNq_fw1200webp"

        # Video generation request (first and last frame mode)
        response = client.videos.generations(
            model="vidu2-start-end",
            image_url=[sample_first_frame, sample_last_frame],  # The first and last frame images
            prompt="Peter Rabbit driving a car, wandering on the road, with a happy and joyful expression on his face.",
            duration=4,  #Video duration (seconds)
            size="1280x720",  # Video resolution
            movement_amplitude="auto",  # Movement amplitude
        )

        # Print the response result
        print(response)
        ```
    </Tab>
</Tabs>

#### Reference-based Video Generation
<Tabs>
    <Tab title="Curl">
        ```json 
        curl --location --request POST 'https://api.z.ai/api/paas/v4/videos/generations' \
        --header 'Authorization: Bearer {your apikey}' \
        --header 'Content-Type: application/json' \
        --data-raw '{
            "model":"vidu2-reference",
            "image_url":["https://example.com/path/to/your/image1.jpg","https://example.com/path/to/your/image2.jpg","https://example.com/path/to/your/image3.jpg"],
            "prompt":"Peter Rabbit drives a small car along the road, his face filled with joy and happiness.",
            "duration":4,
            "aspect_ratio":"16:9",
            "size":"720x480",
            "movement_amplitude":"auto",
            "with_audio":true
        }'
        ```
    </Tab>
    <Tab title="Python">
        ```python
        from zai import ZaiClient

        # Initialize client with your API key (replace 'your-api-key')
        client = ZaiClient(api_key="your-api-key")  

        ref_image_url = [
            "https://gd-hbimg.huaban.com/ccee58d77afe8f5e17a572246b1994f7e027657fe9e6-qD66In_fw1200webp",
            "https://gd-hbimg.huaban.com/cc2601d568a72d18d90b2cc7f1065b16b2d693f7fa3f7-hDAwNq_fw1200webp",
            "https://gd-hbimg.huaban.com/cc2601d568a72d18d90b2cc7f1065b16b2d693f7fa3f7-hDAwNq_fw1200webp"
            ]

        # Generate video using reference images
        response = client.videos.generations(
            model="vidu2-reference",  # Using reference image model
            image_url=ref_image_url,  # List of reference image URLs
            prompt="Peter Rabbit driving a car, wandering on the road, with a happy and joyful expression on his face.",
            duration=4,  # Video duration in seconds
            aspect_ratio="16:9",  # Standard widescreen aspect ratio
            size="1280x720",  # HD resolution
            movement_amplitude="auto",  # Automatic motion control
            with_audio=True,  # Enable audio generation
        )

        # Print API response
        print(response)
        ```
    </Tab>
</Tabs>