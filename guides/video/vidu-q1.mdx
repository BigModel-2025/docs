---
title: "Vidu Q1"
keywords: ["Z.AI","vidu","Vidu Q1","vidu-q1"]
description: "Vidu Q1 is the next-generation video generation model from Vidu, designed for high-quality video creation. It consistently outputs 5-second, 24-frame, 1080P video clips. Through advanced optimization of visual clarity, Vidu Q1 delivers significantly enhanced image quality with notable improvements in issues such as hand distortion and frame jitter. The model achieves photorealistic rendering that closely resembles real-world scenes, while maintaining stylistic accuracy in 2D animation. Transitions between the first and last frames are exceptionally smooth, making Vidu Q1 well-suited for demanding creative applications in film, advertising, and animated short productions."
---

| **Model Version** | **Capabilities**          | **Duration** | **Resolution** | **Price**     |
| :---------------- | :------------------------ | :----------- | :------------- | :------------ |
| viduq1-image      | Image-to-Video Generation | 5s           | 1080p          | \$0.4 / video |
| viduq1-start-end  | Start and End Frame       | 5s           | 1080p          | \$0.4 / video |
| viduq1-text       | Text-to-Video Generation  | 5s           | 1080p          | \$0.4 / video |

### **Capability Description**

- ​**Image-to-Video Generation**​: Generate a video by providing a starting frame or both starting and ending frames along with corresponding text descriptions.
- ​**Start and End Frame**​: Supports input of two images: the first uploaded image is treated as the starting frame, and the second as the ending frame. The model uses these images as input parameters to generate the video.
- ​**Text-to-Video Generation**​: Generate a video from a text prompt; currently supports both a general style and an anime style optimized for animation.

Note: The URL link for the video generated by the model is valid for one day. Please save it as soon as possible if needed.

### **Recommended Use Cases**

| Scenario Type                      | Description                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Film Generation**                | - By inputting script excerpts, concept art, and other materials, users can generate promotional videos, visual effects shots, and auxiliary film assets<br />- Delivers theatrical-level clarity and visual quality with complete frame details<br />- Provides professional-grade video transitions with natural scene flow |
| **Anime Production**               | - Input character designs and storyboard scripts to quickly generate 2D animated sequences and stylized anime shorts<br />- Supports styles such as Chinese animation and Japanese anime<br />- Enables storyline extension and creative regeneration of classic IPs                                                          |
| **Short Drama Production**         | - Automatically generate short videos or micro-dramas from novel chapters or scripted scenes<br />- Covers diverse genres such as romance, mystery, and historical drama<br />- Optimized for multi-platform distribution needs                                                                                               |
| **Advertising & Marketing**        | - Quickly generate highly engaging brand ads, e-commerce product videos, and interactive ads (e.g., virtual try-on) based on product images and feature descriptions<br />- Supports adaptation to various platform dimensions and creative formats                                                                           |
| **Cultural and Tourism Promotion** | - Generate immersive cultural and tourism promo videos or travel MVs in one click using scenic photos and promotional copy<br />- Integrates cultural IPs (e.g., historical artifacts, city icons) to create interactive digital experiences                                                                                  |

### **Resources**

[API Documentation](/api-reference/video/cogvideox-3&vidu): Learn how to call the API.

### **Detailed Description**

1. #### Cinematic-Level Visual Clarity

The model delivers a comprehensive upgrade in visual detail restoration.

<video src="https://cdn.bigmodel.cn/static/platform/videos/usage-guide/vidu/q1-1.mp4" controls />

2. #### Precise Resolution of Visual Artifacts

Movements are smooth and natural—hand gestures during product demonstrations in e-commerce livestreams are accurately rendered and compliant. Visual jitter is minimized through dynamic frame interpolation technology, ensuring fluid and stable footage even in motion-heavy scenes such as running shots or vehicle perspectives.

<video src="https://cdn.bigmodel.cn/static/platform/videos/usage-guide/vidu/q1-2.mp4" controls />

3. #### Multi-Style Artistic Expression

The realistic style aims for lifelike visuals—urban landscapes and character portraits in city promos are rendered with striking realism. The animated style focuses on authenticity, accurately capturing everything from the hand-drawn lines of Japanese anime to the saturated colors of Western cartoons. By inputting anime character designs, the model generates dynamic story segments that closely match the original IP’s visual style, boosting the efficiency of derivative content creation.

Realistic Style:

<video src="https://cdn.bigmodel.cn/static/platform/videos/usage-guide/vidu/q1-3.mp4" controls />

Animated Style:

<video src="https://cdn.bigmodel.cn/static/platform/videos/usage-guide/vidu/q1-4.mp4" controls />

4. #### Industry-Leading Transition Smoothness

The start-to-end frame transition technology reaches a new level, using dynamic frame prediction and style fusion algorithms to overcome the limitations of "mechanical stitching" in video transitions.

![](https://zhipu-ai.feishu.cn/space/api/box/stream/download/asynccode/?code=ZmM4ZjExMTA4MjY1NjhlMWRhODk0ODgzYmY4MzU0YzJfbzR1VHQ0MFZXcWdWMnRJaGhUbmJzOERMTWRxVUdndmlfVG9rZW46UVowTGJ4aG5qb3hLdzh4U2VzcmNaRjlSbmtlXzE3NTA2NzUwNDQ6MTc1MDY3ODY0NF9WNA)

<video src="https://cdn.bigmodel.cn/static/platform/videos/usage-guide/vidu/q1-5.mp4" />

### **Example**

#### Text-to-Video Generation
<Tabs>
    <Tab title="Curl">
        ```json
        curl --location --request POST 'https://api.z.ai/api/paas/v4/videos/generations' \
        --header 'Authorization: Bearer {your apikey}' \
        --header 'Content-Type: application/json' \
        --data-raw '{
            "model": "viduq1-text",
            "style": "anime",
            "prompt": "Peter Rabbit drives a small car along the road, his face filled with joy and happiness.",
            "duration": 5,
            "aspect_ratio": "16:9",
            "size": "1920x1080",
            "movement_amplitude": "auto"
        }'
        ```
    </Tab>
    <Tab title="Python">
        **Install SDK**
        ```bash
        # Install latest version
        pip install zai-sdk

        # Or specify version
        pip install zai-sdk==0.0.2
        ```

        **Verify Installation**
        ```python
        import zai
        print(zai.__version__)
        ```

        ```python
        from zai import ZaiClient

        client = ZaiClient(api_key="your-api-key")
        response = client.videos.generations(
            model="viduq1-text",
            prompt="Peter Rabbit driving a car, wandering on the road, with a happy and joyful expression on his face.",
            style="general",
            duration=5,
            aspect_ratio="16:9",
            size="1920x1080",
            movement_amplitude="auto"
        )

        print(response)
        ```
    </Tab>
</Tabs>

#### Image-to-Video Generation
<Tabs>
    <Tab title="Curl">
        ```json 
        curl --location --request POST 'https://api.z.ai/api/paas/v4/videos/generations' \
        --header 'Authorization: Bearer {your apikey}' \
        --header 'Content-Type: application/json' \
        --data-raw '{
            "model":"viduq1-image",
            "image_url":"https://example.com/path/to/your/image.jpg",
            "prompt":"Peter Rabbit drives a small car along the road, his face filled with joy and happiness.",
            "duration":5,
            "size":"1920x1080",
            "movement_amplitude":"auto"
        }'
        ```
    </Tab>
    <Tab title="Python">
        **Install SDK**
        ```bash
        # Install latest version
        pip install zai-sdk

        # Or specify version
        pip install zai-sdk==0.0.2
        ```

        **Verify Installation**
        ```python
        import zai
        print(zai.__version__)
        ```

        ```python
        from zai import ZaiClient

        client = ZaiClient(api_key="your-api-key")
        response = client.videos.generations(
            model="viduq1-image",
            image_url="https://example.com/path/to/your/image.jpg",
            prompt="Peter Rabbit driving a car, wandering on the road, with a happy and joyful expression on his face.",
            duration=5,
            size="1920x1080",
            movement_amplitude="auto"
        )

        print(response)
        ```
    </Tab>
</Tabs>

#### Start and End Frame
<Tabs>
    <Tab title="Curl">
        ```json 
        curl --location --request POST 'https://api.z.ai/api/paas/v4/videos/generations' \
        --header 'Authorization: Bearer {your apikey}' \
        --header 'Content-Type: application/json' \
        --data-raw '{
            "model":"viduq1-start-end",
            "image_url":["https://example.com/path/to/your/image.jpg","https://example.com/path/to/your/image1.jpg"],
            "prompt":"Peter Rabbit drives a small car along the road, his face filled with joy and happiness.",
            "duration":5,
            "size":"1920x1080",
            "movement_amplitude":"auto"
        }'
```
    </Tab>
    <Tab title="Python">
        **Install SDK**
        ```bash
        # Install latest version
        pip install zai-sdk

        # Or specify version
        pip install zai-sdk==0.0.2
        ```

        **Verify Installation**
        ```python
        import zai
        print(zai.__version__)
        ```

        ```python
        from zai import ZaiClient

        client = ZaiClient(api_key="your-api-key")
        # Define URLs for first frame and last frame
        sample_first_frame = "https://gd-hbimg.huaban.com/ccee58d77afe8f5e17a572246b1994f7e027657fe9e6-qD66In_fw1200webp"
        sample_last_frame = "https://gd-hbimg.huaban.com/cc2601d568a72d18d90b2cc7f1065b16b2d693f7fa3f7-hDAwNq_fw1200webp"

        # Video generation request (first and last frame mode)
        response = client.videos.generations(
            model="viduq1-start-end",
            image_url=[sample_first_frame, sample_last_frame],  # The first and last frame images
            prompt="Peter Rabbit driving a car, wandering on the road, with a happy and joyful expression on his face.",
            duration=5,  #Video duration (seconds)
            size="1920x1080",  # Video resolution
            movement_amplitude="auto",  # Movement amplitude
        )

        # Print the response result
        print(response)
        ```
    </Tab>
</Tabs>

